{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b5f6b7a9-eb37-4f96-ad75-ad72bb5fc89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from models.inference_unet import *\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from torchvision.io import read_image\n",
    "from torchvision import transforms\n",
    "from scipy import ndimage\n",
    "import numpy as np\n",
    "from skimage.color import rgb2lab\n",
    "\n",
    "model = get_trained_unet(model_name='unet_vgg11_upsampling',\n",
    "                         path='./weights/',\n",
    "                         params='unet_params_104_lr_1e-05_h2o2.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "3988e5e3-73cc-4ba2-919d-d3092784ffc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inference(model,\n",
    "                  image_path,\n",
    "                  transform_hr=transforms.Compose([transforms.ToTensor(),transforms.Resize((512,512), antialias=True)]),\n",
    "                  crop = 0.2,\n",
    "                  device = None\n",
    "                  ):\n",
    "  \n",
    "    # get devic\n",
    "     #if not(device):\n",
    "    device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    \n",
    "    # getimage content\n",
    "    img=Image.open(image_path)\n",
    "    \n",
    "    \n",
    "    if crop :\n",
    "        w, h = img.size\n",
    "        left = int(w*crop)\n",
    "        right = int(w - w*crop)\n",
    "        top = int(h*crop)\n",
    "        bottom = int(h - h*crop)\n",
    "        img = img.crop((left,top,right, bottom))\n",
    "        \n",
    "    img_t=transform_hr(img)/255\n",
    "    img_t=img_t.unsqueeze(0)\n",
    "    del img\n",
    "\n",
    "    # prediction\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        mask_pred = model(img_t.to(device))\n",
    "        \n",
    "    _, mask_pred = torch.max(mask_pred, dim=1)\n",
    "    \n",
    "    mask = mask_pred.detach().cpu().squeeze(0).numpy()\n",
    "    del mask_pred\n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    return (img_t.squeeze(0).permute(1,2,0).numpy()*255, (mask*255).astype('uint8'))\n",
    "    # convert single image and store in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "4f23171f-f5c9-4182-9523-53d084451b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def squeeze_mask(image, mask, fac):\n",
    "    '''\n",
    "    reduces mask area by shortening ellipses mmajor and minor axis\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # fit BBoxes\n",
    "    contours = cv2.findContours(mask,  cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours = contours[0] if len(contours) == 2 else contours[1]\n",
    "\n",
    "    bboxes = []\n",
    "    result = np.zeros(image.shape).astype('uint8')\n",
    "    \n",
    "    for i in contours:\n",
    "        x,y,w,h = cv2.boundingRect(i)\n",
    "        if w*h>30 : \n",
    "            bboxes.append([x,y,w,h])\n",
    "\n",
    "    bboxes = np.array(bboxes)\n",
    "    bboxes[:,0] = bboxes[:,0] + bboxes[:,2]/2\n",
    "    bboxes[:,1] = bboxes[:,1] + bboxes[:,3]/2\n",
    "    bboxes[:,2] = (1-fac)*bboxes[:,2]/2\n",
    "    bboxes[:,3] = (1-fac)*bboxes[:,3]/2\n",
    "\n",
    "    for el in bboxes:\n",
    "        cv2.ellipse(result, (el[0],el[1]), (el[2],  el[3]), 0, 0,360, [255,255,255], -1)\n",
    "    \n",
    "    mask_orig = mask\n",
    "    mask = result[:,:,0]\n",
    "\n",
    "    return mask_orig, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "6b15243d-575d-4258-a53a-7fd211ce8def",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_instance_masks(img, mask) -> np.ndarray:\n",
    "    \n",
    "    label_im, nb_labels = ndimage.label(mask) \n",
    "\n",
    "    instance_mask = np.zeros((*img.shape[:2],nb_labels))\n",
    "    for i in range(nb_labels):\n",
    "\n",
    "        mask_compare = np.full(np.shape(label_im), i+1) \n",
    "        separate_mask = np.equal(label_im, mask_compare).astype(int) \n",
    "\n",
    "        separate_mask[separate_mask == 1] = 1\n",
    "\n",
    "        instance_mask[:,:,i] = separate_mask\n",
    "            \n",
    "    #assert instance_mask.shape[-1] == np.array(self.col_list).sum() , 'col_list does not match with instance mask dimension' \n",
    "    \n",
    "    assert np.mod(instance_mask.shape[-1],8) == 0 , 'instance masks are not integer multiple of 8!' \n",
    "    \n",
    "    col_list = [8]*(instance_mask.shape[-1]//8)\n",
    "    \n",
    "    print('col list modified : {}'.format(col_list))\n",
    "\n",
    "    return instance_mask, col_list\n",
    "\n",
    "def sort_instance_masks(instance_mask, col_list, img) :\n",
    "    '''\n",
    "    takes instance mask and group mask accoriding to col_list. Use bounding box estimates on each masks \n",
    "    for sorting.\n",
    "    args :\n",
    "     - instance_mask : ndarray representing num wells containing liquids\n",
    "     - col_list : group columns \n",
    "\n",
    "    reuturns :\n",
    "     - instance_mask_sorted : instance sorted and grouped\n",
    "     - bboxes_sorted : sorted bounding boxes\n",
    "\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    lst_bbox = [] # bbox for sorting\n",
    "    for i in range(instance_mask.shape[2]):\n",
    "        separate_mask = instance_mask[:,:,i]\n",
    "        lst_bbox.append(np.array(get_bboxes(img,separate_mask.astype('uint8'))).ravel())\n",
    "\n",
    "    dummy =[]\n",
    "    dummy_ids =[]\n",
    "    for idx, i in enumerate(lst_bbox):\n",
    "        if i.size > 0 :\n",
    "            if i[2]*i[3]>100 and i.size<5:\n",
    "                dummy.append(i)\n",
    "                dummy_ids.append(idx)\n",
    "\n",
    "    lst_bbox = dummy\n",
    "    instance_mask= instance_mask[:,:,dummy_ids]\n",
    "\n",
    "    lst_bbox = np.array(lst_bbox)\n",
    "\n",
    "    idx = [idx for idx, el in enumerate(lst_bbox) if el.any()]\n",
    "    instance_mask = instance_mask[:,:,idx]\n",
    "    lst_bbox = np.array([lst_bbox[k].tolist() for k in idx])\n",
    "\n",
    "    # x-sort\n",
    "    idx = lst_bbox[:,0].argsort()\n",
    "    lst_bbox = lst_bbox[idx]\n",
    "\n",
    "    instance_mask = instance_mask[:,:,idx]\n",
    "\n",
    "    # ysort provided by user\n",
    "    bboxes_sorted =[]\n",
    "    instance_mask_sorted = []\n",
    "    start = 0\n",
    "    for num in col_list:\n",
    "        bboxes_sorted.append(lst_bbox[start:start+num])\n",
    "        instance_mask_sorted.append(instance_mask[:,:, start:start+num])\n",
    "        start += num\n",
    "\n",
    "    # sort y\n",
    "    #bboxes_sorted2 =#lst_sorted2 =[]\n",
    "    for i, (el,els) in enumerate(zip(bboxes_sorted,instance_mask_sorted)):\n",
    "        idx = el[:,1].argsort()\n",
    "        bboxes_sorted[i] = el[idx]\n",
    "        instance_mask_sorted[i] = els[:,:,idx]\n",
    "\n",
    "    #print(bboxes_sorted)\n",
    "\n",
    "    #instance_mask_sorted = instance_mask_sorted\n",
    "    #self.bboxes_sorted = bboxes_sorted\n",
    "\n",
    "    return instance_mask_sorted, bboxes_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "883db92a-7db5-44fa-9555-7bc0e979760c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_colors_from_patches(\n",
    "                            img,\n",
    "                            instance_mask_sorted,\n",
    "                            mode = 'rgb',\n",
    "                            background_rgb = [255,255,255],\n",
    "                            background_std = np.array([1e-8,1e-8,1e-8]),\n",
    "                            verbose = False):\n",
    "    \n",
    "    color_list =[]\n",
    "    err_list = []\n",
    "            \n",
    "    errfn = lambda r,e1,b,e2 : np.sqrt((1/r)**2 * e1**2 + (1/b)**2 * e2**2)\n",
    "    epsi = 1e-12\n",
    "\n",
    "    img = (img * 255).astype('uint8')\n",
    "\n",
    "    # lab processing\n",
    "    if mode == 'lab':\n",
    "        # lab processing\n",
    "        if verbose : print('running lab mode')\n",
    "        for i in instance_mask_sorted:\n",
    "            mask = i\n",
    "            dummy =[]\n",
    "            dummy_err = []\n",
    "            im1 = np.zeros(img.shape)\n",
    "            for j in range(mask.shape[2]):\n",
    "                im1[:,:,0]= mask[:,:,j] * img[:,:,0]\n",
    "                im1[:,:,1]= mask[:,:,j] * img[:,:,1]\n",
    "                im1[:,:,2]= mask[:,:,j] * img[:,:,2]\n",
    "\n",
    "                lab = rgb2lab(im1[mask[:,:,j]>0].astype('uint8')).mean(axis = 0)\n",
    "                err  = rgb2lab(im1[mask[:,:,j]>0].astype('uint8')).std(axis = 0)\n",
    "\n",
    "                dummy.append(lab.tolist())\n",
    "                dummy_err.append(err.tolist())\n",
    "\n",
    "            color_list.append(dummy)\n",
    "            err_list.append(dummy_err)\n",
    "\n",
    "    else : # rgb-resolved processing\n",
    "        if verbose : print('running rgb-resolved mode')\n",
    "\n",
    "        for i in instance_mask_sorted:\n",
    "            mask = i\n",
    "            dummy =[]\n",
    "            dummy_err = []\n",
    "            im1 = np.zeros(img.shape)\n",
    "            for j in range(mask.shape[2]):\n",
    "                im1[:,:,0]= mask[:,:,j] * img[:,:,0]\n",
    "                im1[:,:,1]= mask[:,:,j] * img[:,:,1]\n",
    "                im1[:,:,2]= mask[:,:,j] * img[:,:,2]\n",
    "                rgb = im1[mask[:,:,j]>0].mean(axis = 0)\n",
    "                err = im1[mask[:,:,j]>0].std(axis = 0)\n",
    "\n",
    "                dummy.append(np.log(background_rgb/(rgb+epsi)).tolist())\n",
    "                dummy_err.append(errfn(rgb,err,background_rgb,background_std).tolist())\n",
    "\n",
    "            color_list.append(dummy)\n",
    "            err_list.append(dummy_err)  \n",
    "\n",
    "\n",
    "    return color_list, err_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "234924f1-fc21-45a4-87db-3f79eca9b120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: only suitable for lab colour model, because it will lack some rgb information under mode 'rgb'\n",
    "def analysis(image_path):\n",
    "    \"\"\" Takes in an RGB image of wells\n",
    "    and computes instance masks for filled wells.\n",
    "    Then computes mean and std lab color for each\n",
    "    well.\n",
    "\n",
    "    out is rows x columns x LAB\n",
    "    \"\"\"\n",
    "    model = get_trained_unet(model_name='unet_vgg11_upsampling',\n",
    "                             path='./weights/',\n",
    "                             params='unet_params_104_lr_1e-05_h2o2.pt')\n",
    "    \n",
    "    out = get_inference(model, image_path)\n",
    "    \n",
    "    img, mask = out\n",
    "    \n",
    "    orig_mask, squeezed_mask = squeeze_mask(img, mask, 0.4)\n",
    "    \n",
    "    instance_mask, col_list = get_instance_masks(img, squeezed_mask)\n",
    "    \n",
    "    im_sorted, bb_sorted = sort_instance_masks(instance_mask, col_list, img)\n",
    "\n",
    "    color_list, err_list = get_colors_from_patches(img, im_sorted, 'lab')\n",
    "\n",
    "    return np.array(color_list), np.array(err_list)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d62a7535-fe3f-47f5-bbdb-9615bf1f2619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mostly operation cell for chemists\n",
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "\n",
    "# create a list to store all the images by giving the file path \n",
    "image_path = Path(r'C:/Users/scrc112/Desktop/work/yuan/20240718/first_trial')\n",
    "\n",
    "image_path = glob.glob(\"*.jpg\")\n",
    "\n",
    "images =[]\n",
    "\n",
    "for imagepath in glob.glob(\"*.jpg\"):\n",
    "    img=cv2.imread(str(imagepath)) \n",
    "    color = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(color)\n",
    "    images.append(img)\n",
    "\n",
    "    \n",
    "for img in image_path:\n",
    "    mean, std = analysis(img)   # mean(x, y), x = column, y = row,std is similar to this \n",
    "\n",
    "   ### more code\n",
    "    \n",
    "    #print(mean[7,1:4])  \n",
    "    #print(mean[3,0:4])\n",
    "    #a, b, c, d = mean[5,0], mean[5,2], mean[5,4], mean[5,6]\n",
    "    #new_array = (a+b+c+d)/4\n",
    "    #print(new_array[2])\n",
    "  \n",
    "    ### save results, e.g. CSV"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ot2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
